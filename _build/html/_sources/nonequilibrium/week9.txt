

Week 9
====================

.. index:: Master Equatioin

.. role:: highlit



Master Equation
-----------------------------



One way of starting somewhere in between instead of starting from microscopic equations to get macroscopic quantities is coarsing the system and use **Master Equation**.



.. math::
   \frac{dP_\xi}{d t} = \sum_{\mu} \left( T_{\xi\mu} P_\mu - T_{\mu\xi} P_\xi \right)

which means the rate of :math:`P_\xi(t)` is determined by the gain and loss of probability.


.. hint::
   **What's the problem of this master equation?**

   It's linear. AND it comes from nowhere.


.. index:: Chapman-Kolmogorov equation

"Derive" Master Equation
--------------------------


One way of deriving master equation is to start from :highlit:`Chapman-Kolmogorov equation` which is

.. math::
   P_\xi(t) = \sum_\mu Q_{\xi\mu} P_\mu(t-\tau) .

This equation describes a discrete and randomwalk process, aka Markov process. In other words, the information about motion is lost with every movement. In this case, all information has been lost before a time interval :math:`\tau`.

The formalism of this equation reminds us the time derivative,

.. math::
   \partial_t P_\xi(t) = \lim \frac{P_\xi(t) - P_\xi(t-\tau)}{\tau} .


To achieve this, notice that

.. math::
   \sum_\mu Q_{\mu\xi} = 1.

.. important::
   It's very important to see this result clearly. Here we write this identity by regarding that the system must jump out of :math:`\xi` state because the summation doesn't include the case that :math:`\mu=\xi`.


Then we can rewrite Chapman-Kolmogorov equation,

.. math::
   P_\xi(t) - P_\xi(t-\tau) = \sum_\mu Q_{\xi\mu}P_\mu(t-\tau) - \sum_\mu Q_{\mu\xi} P_\xi(t-\tau) .

in which we used

.. math::
   P_\xi(t-\tau) = \sum_\mu Q_{\mu\xi} P_\xi(t-\tau) .

Then it seems clear that we can just divide :math:`\tau` on each side and take the limit that :math:`\tau\rightarrow 0`.

.. math::
   \lim_{\tau\rightarrow} \frac{P_\xi(t) - P_\xi(t-\tau)}{\tau} = \lim_{\tau\rightarrow 0} \frac{ \sum_\mu Q_{\xi\mu}P_\mu(t-\tau) - \sum_\mu Q_{\mu\xi} P_\xi(t-\tau) }{\tau}

Watch out. The right hand side goes to infinity usually. One of the way out is to assume that

.. math::
   Q_{ux} = R_{ux}\tau + O(\tau^n)

with :math:`n > 1` which introduces a weird property to the system.

.. warning::
   By saying a system obeys :highlit:`Chapman-Kolmogorov equation` we admit that the system loses information after an time interval :math:`\tau`. Now we take the limit :math:`\tau\rightarrow 0`, which means the system has no memory of the past at all! How to explain this?

   Or can we assume that :math:`P(t-\tau)\propto \tau`?

Anyway, we reach our destination

.. math::
   \partial_t P_\xi(t) = \sum_\mu \left( R_{\xi\mu}P_\mu(t) - R_{\mu\xi}P_\xi(t) \right)  .






.. note::
   Derivation of master equation can be more rigorous. [1]_ This note is a rephrase of Reichl's chapter 6 B. Also refer to Irwin Oppenheim and Kurt E. Shuler's paper. [2]_

   To do this we need to use conditional probability,

   .. math::
      P_1(y_1,t_1) P_{1|1}(y_1,t_1|y_2,t_2) = P_2(y_1,t_1;y_2,t_2)

   which means the probability density of variable Y has value :math:`y_1` at time :math:`t_1` and :math:`y_2` at time :math:`t_2` is given by the probability density of variable Y has value :math:`y_1` at time :math:`t_1` times that of it has value :math:`y_1` at time :math:`t_1` given it has value :math:`y_2` at time :math:`t_2`.




   Assume that :highlit:`the probability density at` :math:`t_n` :highlit:`only depends on that at` :math:`t_{n-1}`, we have

   .. math::
      P_{n-1|1}(y_1,t_1;\cdots;y_{n-1},t_{n-1}|y_n,t_n) = P_{1|1}(y_{n-1},t_{n-1}|y_n,t_n) = P_{1|1}(y_{n-1},t_{n-1}|y_n,t_n) ,

   if we define the variable in a way that :math:`t_1<t_2< \cdots <t_n`.

   **This assumption means that the system is chaotic enough.** This is called **Markov process**.

   Like the transition coefficients :math:`T_{\xi\mu}` we defined previously, this :math:`P_{1|1}(y_{n-1},t_{n-1}|y_n,t_n)` is the **transition probability**.

   To find out the time derivative of :math:`P_1(y_2,t_2)`, we need to write down the time dependence of it,

   .. math::
      P_(y_1,t_1;y_2,t_2) = P_1(y_1,t_1) P_{1|1}(y_1,t_1|y_2,t_2)

   We integrate over :math:`y_1`,

   .. math::
      P_1(y_2,t_2) = \int P_1(y_1,t_1)P_{1|1}(y_1,t_1|y_2,t_2)dy_1

   As we can write :math:`t_2=t_1+\tau`,

   .. math::
      P_1(y_2,t_1+\tau) = \int P_1(y_1,t_1) P _ {1|1}(y_1,t_1|y_2,t_1+\tau) dy_1

   Next we can construct time derivatives of these quantities.

   .. math::
      \partial_{t_1} P_1(y_2,t_1) = \int \lim_{\tau\rightarrow 0} \frac{\int P_1(y_1,t_1) P _ {1|1}(y_1,t_1|y_2,t_1+\tau) - P_1(y_1,t_1) P _ {1|1}(y_1,t_1|y_2,t_1) }{\tau} dy_1


   The next step is the messy one. Expand the right hand side using Taylor series, which one can find in Reichl's book [1]_ , we get the expression for this time derivative,

   .. math::
      \partial_{t} P_1(y_2,t) = \int dy_1 \left( W(y_1,y_2)P_1(y_1,t) - W(y_2,y_1)P_1(y_2,t) \right) .
   This is the :highlit:`master equation`.

   The reason that :math:`W(y_1,y_2)` is an transition rate is that it represents "the probability density perunit time that the system changes from state :math:`y_1` to :math:`y_2` in the time interval :math:`t_1\rightarrow t_1 +\tau` ". [1]_



.. important::

   Now we see that :highlit:`Markov process` is the hypothesis we need to get master equation? DO NOT mistake this with :highlit:`Markov process` ever. There are things unclear in the derivation.

   Read Irwin Oppenheim and Kurt E. Shuler's paper for more details. [2]_

.. note::
   We can find out the :highlit:`Chapman-Kolmogorov equation`

   .. math::
      P_{1|1}(y_1,t_1|y_3,t_3) = \int P _{1|1}(y_1,t_1|y_2,t_2)P_{1|1}(y_2,t_2|y_3,t_3)dy_2

   by comparing the following three equations.

   .. math::
      P_2(y_1,t_1;y_3,t_3) = \int P_3(y_1,t_1;y_2,t_2;y_3,t_3) dy_2

   .. math::
      P_3(y_1,t_1;y_2,t_2;y_3,t_3) = P_1(y_1,t_1) P _{1|1}(y_1,t_1|y_2,t_2) P _{1|1}(y_2,t_2|y_3,t_3)

   .. math::
      \frac{P_2(y_1,t_1;y_3,t_3)}{P_1(y_1,t_1)} = P_{1|1}(y_1,t_1|y_3,t_3)







Examples of Master Equation
------------------------------

Master equation is

.. math::
   \partial_t P_\xi(t) = \sum_\mu \left( R_{\xi\mu}P_\mu(t) - R_{\mu\xi}P_\xi(t) \right) .


Two States Degenerate System
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In such a system master equations are simply

.. math::
   \partial_t P_1 = R (P_2 - P_1)

and

.. math::
   \partial_t P_2 = R (P_1 - P_2) .


To solve the problem, we can choose "canonical coordinates",

.. math::
   P_+ = P_1+P_2

and

.. math::
   P_- = P_1 - P_2 .

By adding the master equations, we have

.. math::
   \partial_t P_+ = 0

and

.. math::
   \partial_t P_- = -2R P_- .



Obviously, the solutions to these equations are

.. math::
   P_+(t) = P_+(0), \qquad P_-(t) = P_-(0)e^{-2Rt} .

This result proves that whatever states was the system in initially, it will get to equilibrium finally.

The term :math:`e^{-2R t}` is a decaying process, or in other words a relaxation process.


.. hint::
   In QM, Von Neumann equations is

   .. math::
      \hat \rho = \hat\rho(0) e^{-i \hat H t/\hbar},

   which is very similar to the solution to the stat mech Liouville equation,

   .. math::
      P(t) = P(0) e^{-A t},

   where A is a matrix

   .. math::
      A_{\xi\mu} = -R_{\xi\mu}, \qquad A_{\xi\xi} = \sum_\mu R_{\mu\xi} .

   The difference here is the :math:`i` in the exponential. Think about decay and rotation.


Non Degenerate Two State System
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In such a system, the transfer matrix is

.. math::
   A = \begin{pmatrix}A_{11}, A{12} \\ A_{21}, A_{22}\end{pmatrix}


Then the master equation for this kind of systems is

.. math::
   \partial_t \begin{pmatrix}P_1 \\ P_2 \end{pmatrix} = \begin{pmatrix}A_{11}, A_{12}\\ A_{21}, A_{22} \end{pmatrix} \begin{pmatrix}P_1 \\ P_2 \end{pmatrix}

We will see similar exponential decaying or growing behaviors as degenerate system. The difference is the equilibrium point.

.. math::
   \partial_t P_1 = R_{12} P_2 - R_{21} P_1

shows us that at equilibrium when :math:`\partial_t P_1 = 0`,

.. math::
   \frac{R_{12}}{R_{21}} = \frac{P_1(\infty)}{P_2(\infty)}

which means the coefficients defines the equilibrium point.


Footnotes
----------



.. [1] L. E. Reichl. "A Modern Course in Statistical Physics".

.. [2] Irwin Oppenheim and Kurt E. Shuler. "Master Equations and Markov Processes". `Phys. Rev. 138, B1007 (1965) <http://journals.aps.org/pr/abstract/10.1103/PhysRev.138.B1007>`_ .
